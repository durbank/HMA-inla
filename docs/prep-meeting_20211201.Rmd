---
title: "AGU Prep Meeting"
output: 
  html_notebook:
    code_folding: hide
---

```{r setup, include=FALSE} 
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

## Intro

I've been playing a little with our HMA modeling and exploring the results some, and I just wanted to go over some of this with everyone and get ideas on how to interpret and present these results.
The main updates I've done are:

- Updating some of the variables (elevation corrections to temperature data, mean climate variables rather than from single years, etc.)
- Exploring the impact of data transformations on results
- Modeling different climate "zones" (based on clustering work) independently from each other
  - Clusters are based on location, elevation, mean annual precipitation, fraction of precipitation during melt season (AMJJAS), mean melt season air temperature, and amplitude of seasonal cycle
- Using training/validation data sets to assess model performance (bias and RMSE)
  - Validation set consists of 1,000 glaciers randomly selected from each of the 5 cluster sets and therefore represents ~5% of the full data set
  - I also have an additional 5,000 glaciers reserved as a final test set

## Key results

The changes to variables and the inclusion/exclusion of data transformations have almost no effect on the final modeled estimates.
A couple of the fixed variable coefficients differ due to these changes, but most are essentially identical.
The inclusion of climate zone clusters in modeling has almost no impact on the accuracy/error of the final MB estimates, but it does have a significant effect on the spatial error term in the model.
It also shows that the individual fixed effects can vary significantly between different clusters.

## Figures and more detailed info

```{r, results=FALSE}
library(here)
library(tidyverse)
library(cetcolor)
library(sf)
library(INLA)
library(INLAutils)
library(spdep)
```

```{r, results=FALSE}
# Import climate/glacier data
dat_sf <- read_sf(here("data/clim_data/glacier_clim.shp"))
dat_correct = read_sf(here("data/glacier-corrected.geojson")) %>% 
  st_drop_geometry() %>% 
  select(RGIId, temp_WARM, T_amp, P_tot, fracP_WARM, Group) %>% 
  rename(T_w = temp_WARM, P_w = fracP_WARM)

dat_sf = dat_sf %>% 
  select(RGIId, mb_mwea, area_km2, 
         z_med, z_aspct, z_slope, hi, 
         east, north, tau, t2_w_18, t2_w_b, 
         ppt_a_18, ppt_a_d, ppt_s_18, ppt_s_d) %>% 
  left_join(dat_correct)



dat <- dat_sf %>% st_drop_geometry() %>% select(-RGIId)

# Log transforms
dat_norm <- dat %>%
  mutate(area_km2 = log(area_km2),
         z_slope = log(z_slope),
         tau = log(tau),
         ppt_s_18 = log(ppt_s_18), 
         T_w = log(T_w), 
         T_amp = log(T_amp), 
         P_tot = log(P_tot)
  )

# Scaling
dat_norm <- dat_norm %>%
  mutate(area_km2 = scale(area_km2),
         z_med = scale(z_med),
         z_aspct = scale(z_aspct),
         z_slope = scale(z_slope),
         hi = scale(hi),
         tau = scale(tau),
         t2_w_18 = scale(t2_w_18),
         t2_w_b = scale(t2_w_b, center = FALSE),
         ppt_a_18 = scale(ppt_a_18),
         ppt_a_d = scale(ppt_a_d, center = FALSE),
         ppt_s_18 = scale(ppt_s_18),
         ppt_s_d = scale(ppt_s_d, center = FALSE), 
         T_w = scale(T_w), 
         T_amp = scale(T_amp), 
         P_tot = scale(P_tot), 
         P_w = scale(P_w, center = FALSE)
         
  )
```

```{r}
set.seed(777)

dat_norm = dat_norm %>% mutate(idarea = 1:nrow(dat_norm))

alpha.list = sort(unique(dat_norm$Group))
idx.list = vector(mode = "list", length = length(alpha.list))
valid.idx = c()

# For each group, hold out 1,000 as a validation set and an additional 5,000 total as test set
for (i in 1:length(alpha.list)) {
  idx.i = which(dat_norm$Group == alpha.list[i])
  idx.list[[i]] = idx.i
  valid.idx = c(valid.idx, sample(idx.i, 1000))
}
test.idx = dat_norm$idarea[!(dat_norm$idarea %in% valid.idx)] %>% 
  sample(5000)

# Add train, test, and valid factors to tibble
dat_norm['Split'] = rep("Train", nrow(dat_norm))
dat_norm[valid.idx,'Split'] = "Valid"
dat_norm[test.idx,'Split'] = "Test"
dat_norm = dat_norm %>% mutate(Split = as.factor(Split))

# Define training data for tranformed results
idx.train = dat_norm$Split == 'Train'
dat.train = dat_norm
dat.train[!idx.train,'mb_mwea'] = NA

# Scaling of untransformed data
dat.scale <- dat %>%
  mutate(area_km2 = scale(area_km2),
         z_med = scale(z_med),
         z_aspct = scale(z_aspct),
         z_slope = scale(z_slope),
         hi = scale(hi),
         tau = scale(tau),
         t2_w_18 = scale(t2_w_18),
         t2_w_b = scale(t2_w_b, center = FALSE),
         ppt_a_18 = scale(ppt_a_18),
         ppt_a_d = scale(ppt_a_d, center = FALSE),
         ppt_s_18 = scale(ppt_s_18),
         ppt_s_d = scale(ppt_s_d, center = FALSE), 
         T_w = scale(T_w), 
         T_amp = scale(T_amp), 
         P_tot = scale(P_tot), 
         P_w = scale(P_w, center = FALSE)
         
  )

# Add valid/test factors for untransformed data
dat.scale = dat.scale %>% mutate(Split = dat_norm$Split, 
                                 idarea = dat_norm$idarea)

# Defin training data for untransformed results
idx.train = dat.scale$Split == 'Train'
train.scale = dat.scale
train.scale[!idx.train,'mb_mwea'] = NA
```

```{r}

# Model priors
prior_bym <- list(prec.unstruct=list(prior='pc.prec',param=c(1, 0.025)),
                  prec.spatial=list(prior='pc.prec', param=c(1, 0.025)))

prior_bym2 <- list(
  prec = list(
    prior = "pc.prec",
    param = c(0.01 / 0.31, 0.01)),
  phi = list(
    prior = "pc",
    param = c(0.5, 2 / 3))
)

# Brewer model without interactions
f.1 <- mb_mwea ~
  t2_w_b + t2_w_18 +
  ppt_a_18 + ppt_a_d +
  ppt_s_18 + ppt_s_d +
  tau + hi +
  z_med + z_slope + z_aspct + area_km2 +
  f(idarea, model = "bym2", graph = g, hyper = prior_bym2)

# Keeler corrections w/out interactions
f.2 = mb_mwea ~
  t2_w_b + T_w +
  P_tot + ppt_a_d +
  P_w + ppt_s_d +
  tau + hi + 
  z_med + z_slope + z_aspct + area_km2 +
  f(idarea, model = "bym2", graph = g, hyper = prior_bym2)

# Brewer model with interactions
f.3 = mb_mwea ~
  t2_w_b * t2_w_18 +
  t2_w_b * ppt_a_18 + ppt_a_d +
  ppt_s_18 + ppt_s_d +
  hi +
  tau * z_med + z_slope + z_aspct + area_km2 +
  f(idarea, model = "bym2", graph = g, hyper = prior_bym2)

# Keeler corrections with interactions
f.4 <- mb_mwea ~
  t2_w_b * T_w +
  t2_w_b * P_tot + ppt_a_d +
  P_w + ppt_s_d +
  hi +
  tau * z_med + z_slope + z_aspct + area_km2 +
  f(idarea, model = "bym2", graph = g, hyper = prior_bym2)

f.list = c(f.1, f.2, f.3, f.4)
```

```{r}
# mod.list = vector(mode = "list", length = length(f.list))
# for (i in 1:length(mod.list)) {
#   system.time(
#     results.i <- inla(f.list[[i]], data = dat.train, 
#                  control.predictor = list(compute = TRUE), 
#                  control.compute = list(dic = TRUE, waic = TRUE))
#   )
#   mod.list[[i]] = results.i
# }

# system.time(
#   results <- inla(f.4, data = train.scale,
#                control.predictor = list(compute = TRUE),
#                control.compute = list(dic = TRUE, waic = TRUE))
# )
# 
# 
# mod.list = append(mod.list, list(results))
```

```{r}

# Modeling with climate clusters

dat.group = dat.scale
alpha.list = sort(unique(dat.group$Group))

# Create neighbor network for each group
for (i in alpha.list) {
  dat.i = dat.group %>% filter(Group == i)
  
  # INLA spatial graph
  # crds <- st_coordinates(dat_sf)
  coo <- cbind(dat.i$east / 1000,
               dat.i$north / 1000)
  
  fn.i = here("data", 
              paste("map_", i, ".adj", sep = ''))
  
  # Only perform calculation if file does not exist
  if (!(file.exists(fn.i))) {
    nb <- graph2nb(gabrielneigh(coo), sym = TRUE)
    nb2INLA(fn.i, nb)
  }
  
}

```

```{r}
# # Model priors
# prior_bym2 <- list(
#   prec = list(
#     prior = "pc.prec",
#     param = c(0.01 / 0.31, 0.01)),
#   phi = list(
#     prior = "pc",
#     param = c(0.5, 2 / 3))
# )
# 
# group.mods = vector(mode = "list", length = length(alpha.list))
# for (i in 1:length(group.mods)) {
#   
#   # Subset data and remove valid/test values
#   dat.i = dat.group %>% filter(Group == alpha.list[i])
#   idx.train = dat.i$Split == 'Train'
#   dat.i[!idx.train,'mb_mwea'] = NA
#   
#   # Reset idarea index (necessary to match new neighbor graphs)
#   dat.i['idarea'] = 1:nrow(dat.i)
#   
#   # Load neighbor graph
#   nb.fn = here("data", paste("map_", alpha.list[i], 
#                              ".adj", sep = ""))
#   g = inla.read.graph(nb.fn)
#   
#   # # Corrected model without interactions
#   # f.i = mb_mwea ~
#   #   t2_w_b + T_w +
#   #   P_tot + ppt_a_d +
#   #   P_w + ppt_s_d +
#   #   tau + hi + 
#   #   z_med + z_slope + z_aspct + area_km2 +
#   #   f(idarea, model = "bym2", graph = g, hyper = prior_bym2)
#   
#   # Corrected model with interactions
#   f.i =  mb_mwea ~
#     t2_w_b * T_w +
#     t2_w_b * P_tot + ppt_a_d +
#     P_w + ppt_s_d +
#     hi +
#     tau * z_med + z_slope + z_aspct + area_km2 +
#     f(idarea, model = "bym2", graph = g, hyper = prior_bym2)
#   
#   system.time(
#     results.i <- inla(f.i, data = dat.i,
#                       control.predictor = list(compute = TRUE),
#                       control.compute = list(dic = TRUE, waic = TRUE))
#   )
#   group.mods[[i]] = results.i
# }
# saveRDS(group.mods, here("data", "models_group.rds"))

```

### Validation and comparisons of models

```{r}
get_results = function(df, geo, model, group=FALSE) {
  
  
  if (group) {
    
    # if (length(model) < 2) {
    #   print("Error: Wrong number of models provided for grouping")
    #   flag = 1
    # }
    
    grp.list = sort(unique(df$Group))
    for (i in 1:length(grp.list)) {
      
      df.i = df %>% filter(Group == grp.list[i])
      mod.i = model[[i]]
      pred.i = mod.i$summary.fitted.values$mean
      pred_sd.i = mod.i$summary.fitted.values$sd
      re.i = mod.i$summary.random$idarea$mean[1:nrow(df.i)]
      
      df[df.i$idarea,'pred'] = pred.i
      df[df.i$idarea,'pred_sd'] = pred_sd.i
      df[df.i$idarea,'spat.re'] = re.i
    }
    
  } else {
    
    df['pred'] = model$summary.fitted.values$mean
    df['pred_sd'] = model$summary.fitted.values$sd
    df['spat.re'] = model$summary.random$idarea$mean[1:nrow(df)]
  }
  
  df = df %>% mutate(error = mb_mwea-pred)
  df['geometry'] = geo
  df = df %>% st_as_sf()
}
```

```{r}
# Load modeling results
mod.list = readRDS(here("data/models_latest.rds"))
group.mods = readRDS(here("data/models_group.rds"))

# Extract desired results from full model outputs for global models
results = vector(mode = "list", length = length(mod.list))
for (i in 1:length(mod.list)) {
  mod.i = mod.list[[i]]
  results[[i]] = get_results(df = dat_norm %>% select(idarea, Group, Split, mb_mwea), 
                             geo = dat_sf['geometry'], 
                             model = mod.i, 
                             group = FALSE)
}

# Extract desired results from full model outputs for group results
results = append(results, list(get_results(df = dat.group %>% 
                                             select(idarea, Group, Split, mb_mwea), 
                                           geo = dat_sf['geometry'], 
                                           model = group.mods, 
                                           group = TRUE))
)

bias_vec = vector(mode = "numeric", length = length(results))
rmse_vec = vector(mode = "numeric", length = length(results))
pred.err = vector(mode = "numeric", length = length(results))
df_plt = tibble()
mod.names = c("Model.1", "Model.2", "Model.3", 
              "Model.4", "Model.5", "Model.6")
for (i in 1:length(results)) {
  dat.valid = results[[i]] %>% filter(Split == 'Valid')
  bias_vec[i] = mean(dat.valid$error)
  rmse_vec[i] = sqrt(mean(dat.valid$error^2))
  pred.err[i] = mean(dat.valid$pred_sd)
  
  row.i = tibble("Name" = mod.names[i], "Residual" = dat.valid$error)
  df_plt = bind_rows(df_plt, row.i)
}

p1 = ggplot(df_plt, aes(x=Residual, group = Name, color = Name)) + 
  geom_density() + xlim(-1,1)
print(p1)

res_tbl = as_tibble(data.frame("Name" = mod.names, "Bias" = bias_vec, 
                               "RMSE" = rmse_vec, "Pred.err" = pred.err))
print(res_tbl)
```

As can be seen in the above figure and table, there is essentially no difference in final MB results between the various models, based on bias and RMSE stats from the validation hold out sets.
The different models included are as follows:

- Model.1: Original Brewer model without corrections or interactions
- Model.2: Climate variable corrections without interactions
- Model.3: Original model with interactions
- Model.4: Climate variable corrections with interactions
- Model.5: Climate variable corrections (no interactions) on untransformed data
- Model.6: Climate variable corrections (with interactions) on untransformed data, broken down into 5 clustered climate zones

### Differences in fixed effects

```{r, fig.width=12}

mod.marg = tibble()
mod.names = c("Model.1", "Model.2", "Model.3", 
              "Model.4", "Model.5")
for (i in 1:length(mod.list)) {
  mod.i = mod.list[[i]]$summary.fixed
    var.names = row.names(mod.i)
    for (j in 1:length(var.names)) {
      lb.j = mod.i$`0.025quant`[j]
      mu.j = mod.i$mean[j]
      ub.j = mod.i$`0.975quant`[j]
      marg.j = tibble(val.lb=lb.j, val.mu=mu.j, val.ub=ub.j, var=var.names[j], Group=mod.names[i])
      mod.marg = mod.marg %>% bind_rows(marg.j)
    }
}

insig.idx = mod.marg['val.lb'] < 0 & mod.marg['val.ub'] > 0
mod.marg['Significant'] = TRUE
mod.marg[insig.idx, 'Significant'] = FALSE
mod.marg = mod.marg %>% mutate(var=as.factor(var), Group=as.factor(Group))


ggplot(mod.marg, aes(y = var, x = val.mu, xmin = val.lb, xmax = val.ub, color=Significant)) + 
  geom_vline(xintercept = 0, colour = "black", lty = 2) +
  geom_point() + 
  geom_errorbarh(height = 0) + 
  scale_color_manual(values = c("TRUE" = "red", "FALSE" = "black")) + 
  facet_grid(. ~ Group, scales = "free")

# for (i in 1:length(mod.list)) {
#   print(plot_fixed_marginals(mod.list[[i]]))
# }
```
These show the marginal posterior distributions for fixed effects for the first 5 models.
I could be interpreting this wrong, but I think the corrections and changes really only affect the scaling/centering/etc of the results and all of these models are essentially equivalent if they were all transformed into uniform space (although there are some slight changes in significant/insignificant effects between the models).

The next set of plots shows the marginal posterior distributions for fixed effects for each of the climate zones (A-E) using Model.6.
This is followed by a figure showing the spatial distribution of the clustering.
As can been seen, the fixed effects parameters can vary significantly between clusters.

```{r, fig.width=12}

group.marg = tibble()
for (i in 1:length(group.mods)) {
  mod.i = group.mods[[i]]$summary.fixed
    var.names = row.names(mod.i)
    for (j in 1:length(var.names)) {
      lb.j = mod.i$`0.025quant`[j]
      mu.j = mod.i$mean[j]
      ub.j = mod.i$`0.975quant`[j]
      marg.j = tibble(val.lb=lb.j, val.mu=mu.j, val.ub=ub.j, var=var.names[j], Group=alpha.list[i])
      group.marg = group.marg %>% bind_rows(marg.j)
    }
}

insig.idx = group.marg['val.lb'] < 0 & group.marg['val.ub'] > 0
group.marg['Significant'] = TRUE
group.marg[insig.idx, 'Significant'] = FALSE
group.marg = group.marg %>% mutate(var=as.factor(var), Group=as.factor(Group))

ggplot(group.marg, aes(y = var, x = val.mu, xmin = val.lb, xmax = val.ub, color=Significant)) + 
  geom_vline(xintercept = 0, colour = "black", lty = 2) +
  geom_point() + 
  geom_errorbarh(height = 0) + 
  scale_color_manual(values = c("TRUE" = "red", "FALSE" = "black")) + 
  xlim(c(-0.7, 0.3)) + 
  facet_grid(. ~ Group, scales = "free")

```

```{r}
ggplot(dat_sf, aes(color=Group)) + geom_sf(alpha=0.5)
```

### Spatial random effect

When looking at the spatial random effect, Models 1-5 are essentially identical, so I only use one of them (Model.2) and compare it to the spatial random effect of the clustered model results.

```{r}
# All the global models are essentially identical, so only use one
mod.num = 2

gbl.mod = results[[mod.num]] %>% 
  mutate(y.fixed = pred-spat.re)

c_max = max(abs(c(quantile(gbl.mod$mb_mwea, 0.005), 
          quantile(gbl.mod$mb_mwea, 0.995))))
clims = c(-c_max, c_max)
ggplot(gbl.mod %>% filter(Split=='Valid'),
       aes(color=y.fixed)) + geom_sf() + 
  scale_color_gradientn(colors = rev(cet_pal(5, name = "d1a")), 
                        limits=clims)
ggplot(gbl.mod %>% filter(Split == 'Valid'), 
       aes(color=spat.re)) + 
  geom_sf() + 
  scale_color_gradientn(colors = rev(cet_pal(5, name = "d1a")), 
                        limits=clims)
ggplot(gbl.mod %>% filter(Split=='Valid'), 
       aes(color=pred)) + geom_sf() + 
  scale_color_gradientn(colors = rev(cet_pal(5, name = "d1a")), 
                        limits=clims)
mb_plt = ggplot(gbl.mod %>% filter(Split=='Valid'), 
       aes(color=mb_mwea-pred)) + geom_sf() + 
  scale_color_gradientn(colors = rev(cet_pal(5, name = "d1a")), 
                        limits=clims) + 
  labs(color = "Error")
print(mb_plt)
```
The above figures show the estimated mass balance for Models 1-5 (1) without the spatial random effect, (2) just the spatial random effect, (3) the combined fixed+random estimate, and (4) the residuals between observed and modeled (fixed+random) mass balance.
The glaciers shown are only the 5,000 used as validation (i.e. not directly incorporated in the model training).
As can be seen, the random effect dominates over the fixed effects, and frequently even shifting the sign of the combined prediction.
The fixed effects completely miss the Karakoram Anomaly and only predict weakly positive balances for the south-central Tibetean Plateau.

The same figures for the clustered model (shown below) seem to better match reality, as far as the fixed effects go, but the strongest effect still seems to be the spatial random effect.

```{r}

grp.mod = last(results) %>% 
  mutate(y.fixed = pred-spat.re)

c_max = max(abs(c(quantile(grp.mod$mb_mwea, 0.005), 
          quantile(grp.mod$mb_mwea, 0.995))))
clims = c(-c_max, c_max)
ggplot(grp.mod %>% filter(Split=='Valid'),
       aes(color=y.fixed)) + geom_sf() + 
  scale_color_gradientn(colors = rev(cet_pal(5, name = "d1a")), 
                        limits=clims)
ggplot(grp.mod %>% filter(Split == 'Valid'), 
       aes(color=spat.re)) + 
  geom_sf() + 
  scale_color_gradientn(colors = rev(cet_pal(5, name = "d1a")), 
                        limits=clims)
ggplot(grp.mod %>% filter(Split=='Valid'), 
       aes(color=pred)) + geom_sf() + 
  scale_color_gradientn(colors = rev(cet_pal(5, name = "d1a")), 
                        limits=clims)
mb_plt = ggplot(grp.mod %>% filter(Split=='Valid'), 
       aes(color=mb_mwea-pred)) + geom_sf() + 
  scale_color_gradientn(colors = rev(cet_pal(5, name = "d1a")), 
                        limits=clims) + 
  labs(color = "Error")
print(mb_plt)
```

The final figures below show (1) the distribution of total error for the global and clustered model, the residual error broken out by cluster for the global and grouped model (2 and 3), and the magnitude of the spatial random effect for the global and group models, again broken out for each cluster (4 and 5).

```{r}

err.lims = c(quantile(gbl.mod$error, 0.005), 
             quantile(gbl.mod$error, 0.995))
colors <- c("Global" = "red", "Grouped" = "blue")
ggplot() + 
  geom_density(data=gbl.mod, aes(x=error, color="Global")) + 
  geom_density(data=grp.mod, aes(x=error, color="Grouped")) + 
  xlim(err.lims) + labs(x="Error", color="Model") + 
    scale_color_manual(values = colors)


ggplot(gbl.mod, aes(x=error, group=Group, color=Group)) + 
  geom_density() + xlim(err.lims) + xlab("Global Error")
ggplot(grp.mod, aes(x=error, group=Group, color=Group)) + 
  geom_density() + xlim(err.lims) + xlab("Grouped Error")


re.lims = c(quantile(gbl.mod$spat.re, 0.005), 
            quantile(gbl.mod$spat.re, 0.995))
ggplot(gbl.mod, aes(x=spat.re, group=Group, color=Group)) + 
  geom_density() + xlim(re.lims) + xlab("Global random effect")
ggplot(grp.mod, aes(x=spat.re, group=Group, color=Group)) + 
  geom_density() + xlim(re.lims) + xlab("Grouped random effect")
```